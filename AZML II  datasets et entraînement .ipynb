{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azml II datasets - trainings\n",
    "Laurent Cetinsoy\n",
    "\n",
    "Dans ce notebook on continue notre exploration d'AZML avec les Datasets, les entraînements avec AZML, la notion de compute target, d'inference config et de déploiement\n",
    "\n",
    "\n",
    "## Datasets\n",
    "\n",
    "Azml permet de gérer ses propres dataset avec la class... Tada... Dataset. \n",
    "La classe comporte plusieurs classes filles. Quelles sont elles?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TabularDataset et FileDataset elles sont dans le module azureml.data.Tabulare pour TabularDataset\n",
    "\n",
    "Remarque il existe aussi la classe azureml.core.Dataset\n",
    "\n",
    "**Attention** ne pas confondre `Datastore` et `Dataset`, quelle différence entre les deux classes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelles sont les méthodes importantes de la classe `Datastore` ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelles sont les méthodes importantes de la classe `Dataset` ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger le workspace créé lors du précédent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide du bon Datastore, uploader le fichier dataset1 dans le datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide du datastore, uploader le fichier dataset1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer une référence vers ce dataset avec la classe Dataset.Tabular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher avec le sdk la liste de tous les datasets disponibles de votre workspace. Est-ce normal ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que le dataset n'est pas présent, en effet il faut le register nous même. Register le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher à nouveau le dataset et vérifier sur le portail aussi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel : un datastore ça représente un mécanisme de stockage. \n",
    "\n",
    "Si vous regardez dans la doc, il existe deux types de Datastore. Un qui FileDatastore, BlobStorageDatastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le  défaut datastore (blob storage datastore), upload va uploader les fichiers sur un blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer la première colonne du dataset et afficher le dataset avec la méthode to_pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuploader le dataset en changeant de nom l'upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Toujours en utilisant ces fameux objets `Dataset`, faire un split du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher le resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploader le dataset2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-il possible de concatener les deux datasets horizontalement ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Si c'est possible, concatener les deux dataset au sein d'un même objet dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-il possible faire un join comme en pandas avec la classe Dataset ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori ce n'est pas possible mais peut être que je me trompe. Pour moi la classe dataset n'a **pas** vocation a remplacer pandas mais à simplement manipuler les dataset sur Azure machine learning \n",
    "Néanmoins, elle  propose quelques qui peuvent être utiles dans le cas du ML (split, sample, etc) mais ça reste basique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement version II\n",
    "\n",
    "Dans le notebook précédent, on a entraîné notre modèle nous même et on a ajouté des run.log. \n",
    "\n",
    "Azml propose aussi des outils pour gérer l'entraînement des modèles. L'idée est d'avoir son fichier d'entraînement sur son pc et de l'envoyer sur l'environnement d'entraînement de votre choix (une ressource azure bien entendu) ou en local.\n",
    "\n",
    "Pour cela on va avoir besoin notamment classes ComputeTarget et Estimator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aller sur la page de la classe Estimator, à quoi sert-elle ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelles sont les sous classes principales et les méthodes principales ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une experiment rattaché à votre workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprendre la petite fonction d'hier d'entraînement du modèle et la mettre dans un fichier \"train.py\".\n",
    "Récupérer une variable run au début du script et faire en sorte que l'entraînement soit lancé chaque fois qu'on lance le script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une instance de SkLearn Estimator qui utilise le fichier train.py\n",
    "\n",
    "Références utiles :\n",
    "- https://docs.microsoft.com/fr-fr/python/api/azureml-train-core/azureml.train.sklearn.sklearn?view=azure-ml-py\n",
    "\n",
    "- https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/ml-frameworks/scikit-learn/training/train-hyperparameter-tune-deploy-with-sklearn/train-hyperparameter-tune-deploy-with-sklearn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancer l'entraînement de votre estimator avec la méthode experiment.submit. Utiliser l'argument show_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifier que ça marche : l'entraînement est bien lancé et que les résultats sont bien visibles sur le dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifier le script pour qu'après chaque entraînement le modèle soit sauvegardé dans un sous dossier output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement sur environement distant \n",
    "\n",
    "On va adapter notre entraînement pour que ça marche à distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une Azml Compute Instance  grâce à la méthode provisioning_configuration de la classe AmlCompute. Il va retourne un objet de type ComputeConfig\n",
    "\n",
    "**IL FAUDRA SUPPRIMER LA COMPUTE INSTANCE EN ALLANT DANS VOTRE WORKSPACE DANS LE PORTAIL ET CLIQUE SUR COMPUTE INSTANCE ET COMPUTE CLUSTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à l'objet, créer une ComputeTarget qui référence le AmlCompute qui vient d'être créé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un autre Sklearn estimator qui utilise la compute nouvellement créé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une nouvelle experience et la submit à l'aide de l'estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifier que ça marche et debug si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
